package ru.yandex;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.GlobalKTable;
import org.apache.kafka.streams.kstream.Grouped;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;
import ru.yandex.blockList.model.Blocklist;
import ru.yandex.blockList.serializer.BlocklistSerdes;
import ru.yandex.message.model.Message;
import ru.yandex.message.serialization.MessageSerdes;
import ru.yandex.wordAccumulator.model.WordAccumulator;
import ru.yandex.wordAccumulator.serialization.WordAccumulatorSerdes;
import ru.yandex.wordContext.model.WordContext;
import ru.yandex.wordContext.serialization.WordContextSerdes;

import java.util.ArrayList;
import java.util.List;
import java.util.Properties;

@Slf4j
@Component
@RequiredArgsConstructor
public class FilterProcessorUtils {

    @Value("${spring.kafka.topic.filtered}")
    private String TOPIC_NAME = "filtered";

    public void runFilterProcessor() {
        Properties properties = new Properties();
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, "message-filter-processor");
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka-broker-0:9092,kafka-broker-1:9092,kafka-broker-2:9092");

        StreamsBuilder builder = new StreamsBuilder();

        // 1. –ß–∏—Ç–∞–µ–º GlobalKTable —Å –±–ª–æ–∫–ª–∏—Å—Ç–æ–º
        GlobalKTable<String, Blocklist> blocklistTable = builder.globalTable(
                "blocklist",
                Consumed.with(Serdes.String(), new BlocklistSerdes())
        );

        // 2. –ß–∏—Ç–∞–µ–º GlobalKTable —Å –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        GlobalKTable<String, String> censureTable = builder.globalTable(
                "censure",
                Consumed.with(Serdes.String(), Serdes.String())
        );

        // 3. –ü–æ—Ç–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        KStream<String, Message> messageStream = builder.stream(
                "message",
                Consumed.with(Serdes.String(), new MessageSerdes())
        ).peek((key, message) ->
                log.info("üì• Received message: key={}, value={}", key, message.toString())
        );
        ;

        // 4. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –±–ª–æ–∫–ª–∏—Å—Ç—É
        KStream<String, Message> filteredStream = messageStream
                .join(
                        blocklistTable,
                        (messageKey, message) -> {
                            log.info("üîç Checking blocklist for key: {}", message.getFrom());
                            return String.valueOf(message.getFrom());
                        }, // –∫–ª—é—á –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –±–ª–æ–∫–ª–∏—Å—Ç
                        (message, blocklist) -> {
                            if (blocklist == null) {
                                log.info("‚úÖ Message approved (no blocklist entry): {}", message.toString());
                                return message; // –Ω–µ—Ç –±–ª–æ–∫–ª–∏—Å—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            }

                            if (blocklist.getBlocklist().contains(message.getFrom())) {
                                log.warn("‚õî Message blocked: sender {} in blocklist", message.getFrom());
                                return null; // –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω ‚Äî —É–¥–∞–ª—è–µ–º
                            }
                            log.info("‚úÖ Message approved: {}", message);
                            return message;
                        }
                )
                .filter((key, message) -> {
                    log.debug("üóëÔ∏è Filtered out null message");
                    return message != null;
                });

        // 5. –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å–ª–æ–≤–∞
        KStream<String, WordContext> wordsStream = filteredStream
                .peek((key, message) -> log.info("‚úÇÔ∏è Splitting message into words: {}", message.getText()))
                .flatMap((key, message) -> {
                            List<KeyValue<String, WordContext>> splitWords = new ArrayList<>();
                            String[] wordArray = message.getText().split("\\s+");

                            for (int i = 0; i < wordArray.length; ++i) {
                                splitWords.add(KeyValue.pair(
                                        wordArray[i],
                                        WordContext.builder()
                                                .from(message.getFrom())
                                                .to(message.getTo())
                                                .messageId(message.getId())
                                                .order(i)
                                                .replacement(wordArray[i])
                                                .build()
                                ));
                            }

                            return splitWords;
                        }
                );

        // 6. –ó–∞–º–µ–Ω–∞ –ø–ª–æ—Ö–∏—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ join —Å —Ü–µ–Ω–∑—É—Ä–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ–π
        KStream<String, WordContext> censoredWordsStream = wordsStream
                .peek((word, context) -> log.info("üî† Processing word: {}", word))
                .leftJoin(
                        censureTable,
                        (word, context) -> {
                            log.debug("üîé Looking up word in censure table: {}", word);
                            return word;
                        },
                        (context, replacement) -> {
                            if (replacement != null) {
                                log.info("üö´ Censored word: {} -> {}", context.getReplacement(), replacement);

                                context.setReplacement(replacement);
                            }

                            log.info(context.getOriginal());
                            return context;
                        }
                );

        // 7. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ —Å–±–æ—Ä–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
        KStream<Long, Message> censoredMessages = censoredWordsStream
                .peek((word, context) -> log.info("üß© Assembling message parts for ID: {}", context.getMessageId()))
                .groupBy(
                        (word, context) -> context.getMessageId(), // –∫–ª—é—á - —É–Ω–∏–∫–∞–ª—å–Ω—ã–π id —Å–æ–æ–±—â–µ–Ω–∏—è
                        Grouped.with(Serdes.Long(), new WordContextSerdes())
                )
                .aggregate(
                        WordAccumulator::new,
                        (key, wordContext, accumulator) -> accumulator.addWord(wordContext),
                        Materialized.with(Serdes.Long(), new WordAccumulatorSerdes())
                )
                .toStream()
                .mapValues(WordAccumulator::toMessage);

        // 8. –í—ã–≤–æ–¥ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–æ–ø–∏–∫
        censoredMessages.peek((key, message) ->
                        log.info("‚úâÔ∏è Sending to output topic {}: key={}, value={}", TOPIC_NAME, key, message))
                .to(TOPIC_NAME, Produced.with(Serdes.Long(), new MessageSerdes()));

        // 9. –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        KafkaStreams streams = new KafkaStreams(builder.build(), properties);
        streams.start();

        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            log.info("Shutting down Kafka Streams...");
            streams.close();
        }));
    }
}
